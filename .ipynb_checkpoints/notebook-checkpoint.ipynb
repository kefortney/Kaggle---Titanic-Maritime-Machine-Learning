{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "-------\n",
    "\n",
    "On April 15, 1912 the RMS Titanic carrying 2,224 passengers (including crew) struck an iceberg and over the next two hours slid below the icy waves along with over 1,500 dead by the time the RMS Carpathia over 6 hours later.  Oddly enough, the RMS Titanic was actually carrying more lifeboats than required by law which was based on gross tonnage, not number of passengers.  If every life boat has been successfully launched at full capacity (most were not fully loaded and two drifted away as she sunk) there would have only been room for 1,178 in total, still well shy the number of people aboard.\n",
    "\n",
    "This is an exploration of using machine learning to determine factors in survival.  The dataset is of passengers only (crew numbered about 885 people and a survival rate of around 24%).  Titanic's passengers numbered approximately 1,317 people: 324 in First Class, 284 in Second Class, and 709 in Third Class but this data set has a total pf 1,309 passenger records.  If the RMS Titanic had a full ship of 3,339 passengers and crew the accident would have been much deadlier\n",
    "\n",
    "The Data\n",
    "--------\n",
    "\n",
    "* PassengerId \tUnique Identifier\n",
    "* Survival        Survival (0 = No; 1 = Yes)\n",
    "* Pclass 1 = First Class, 2 = Second Class, 3 = Third Class\n",
    "* Name Last Name, Surname First Name and additional qualifier if needed\n",
    "* Sex  Male or Female\n",
    "* Age\tAge, Fractional if Age less than One (1) If the Age is Estimated, it is in the form xx.5\n",
    "* SibSp\tNumber of Siblings/Spouses Aboard\n",
    "* Parch\tNumber of Parents/Children Aboard\n",
    "* Ticket\tTicket Number\n",
    "* Fare\tPassenger Fare\n",
    "* Cabin\tCabin with the letter being deck and number is cabin, decks should be A-G\n",
    "* Embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "**PLEASE NOTE THIS IS IN PROGRESS AND HAS NOT BEEN COMPLETED**\n",
    "\n",
    "As this is my first foray into machine learning, please comment below with any suggestions or notes!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# sns.set_style('whitegrid',{'axes.grid' : False})\n",
    "# sns.set_context(rc = {'patch.linewidth': 0.0})\n",
    "# bar_settings = {'color': sns.xkcd_rgb['grey'], 'ci': None}\n",
    "# color_settings = {'color': sns.xkcd_rgb['grey']}\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Selection and Cleaning\n",
    "---------------------------\n",
    "\n",
    "First I wanted to get an understanding of the data and see how many are missing values.  At first I need to import from csv's both the training and the test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'C:\\\\Users\\\\kefor/Desktop/pythonexplore/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fd242a6836f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# get titanic & test csv files as a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~/Desktop/pythonexplore/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~/Desktop/pythonexplore/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# if you want to see where values are missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kefor\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kefor\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kefor\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kefor\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kefor\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'C:\\\\Users\\\\kefor/Desktop/pythonexplore/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# get titanic & test csv files as a DataFrame\n",
    "train_df = pd.read_csv(\"~/Desktop/pythonexplore/train.csv\")\n",
    "test_df = pd.read_csv(\"~/Desktop/pythonexplore/test.csv\")\n",
    "\n",
    "# if you want to see where values are missing\n",
    "print(\"THIS IS THE TRAIN_DF INFO\")\n",
    "train_df.info()\n",
    "print(\"-------------------------\")\n",
    "print(\"THIS IS THE TEST_DF INFO\")\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data\n",
    "-------------\n",
    "\n",
    "There are some missing values, some are simpler than others. The first one is a quick fill for the missing single fare with the median value.  A quick check shows that most of the nulls are under Age and Cabin and we will deal with them next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7205a9121b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Embarked only in train_df, fill the two missing values with the most occurred value, which is \"S\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Embarked\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Embarked\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# Fill in the single missing fare with median value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Fare\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Fare\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Embarked only in train_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Fill in the single missing fare with median value\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Convert fare from float to int\n",
    "train_df['Fare'] = train_df['Fare'].astype(int)\n",
    "test_df['Fare'] = test_df['Fare'].astype(int)\n",
    "\n",
    "# Count all the null values\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Missing Ages\n",
    "--------------------\n",
    "\n",
    "There is a fair number of missing age.  First I need to understand what the distribution looks like currently so I can check after I run RandomForestRegressor to make sure that it doesn't look off.  [Poonam's work][1] was an amazing asset as this is all new to me. \n",
    "\n",
    "  [1]: https://www.kaggle.com/poonaml/titanic/titanic-survival-prediction-end-to-end-ml-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-46435b76b1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Quick histogram of age with NaN's ignored so it will plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick histogram of age with NaN's ignored so it will plot\n",
    "plt.hist(train_df['Age'].dropna(),bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#predicting missing values in age using Random Forest\n",
    "def fill_missing_age(df):\n",
    "    \n",
    "    #Feature set\n",
    "    age_df = df[['Age','Pclass','SibSp','Parch','Fare']]\n",
    "    # Split sets into train and test\n",
    "    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n",
    "    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n",
    "    \n",
    "    # All age values are stored in a target array\n",
    "    y = train.values[:, 0]\n",
    "    \n",
    "    # All the other values are stored in the feature array\n",
    "    X = train.values[:, 1::]\n",
    "    \n",
    "    # Create and fit a model\n",
    "    rtr = RandomForestRegressor(n_estimators=4000, n_jobs=-1)\n",
    "    rtr.fit(X, y)\n",
    "    \n",
    "    # Use the fitted model to predict the missing values\n",
    "    predictedAges = rtr.predict(test.values[:, 1::])\n",
    "    \n",
    "    # Assign those predictions to the full data set\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a4d24665aa04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Now apply the function to the data for both training and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_missing_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_missing_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# Verify that the NaNs are no longer there for age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Now apply the function to the data for both training and test data\n",
    "train_df=fill_missing_age(train_df)\n",
    "test_df=fill_missing_age(test_df) \n",
    "\n",
    "# Verify that the NaNs are no longer there for age\n",
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the final result after changing the Ages to make sure it looks similiar in distribution and then do a quick sanity check with describe to make sure nothing went negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7ead74c3ca8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(train_df['Age'],bins=20)\n",
    "plt.show()\n",
    "train_df['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "-------------------\n",
    "\n",
    "In order to make the machine learning be more accurate some feature engineering is needed.  Cabin is only moderately useful, I cannot really create the correct cabin placements without going somewhere else to get that information.  The Third Class passenger cabins in the bow was under water in less than 20 minutes after the strike, but there were also cabins in the stern as well.  \n",
    "\n",
    "First I am going to focus on Names and pulling some more information out of those.  Poonam's work again was vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Sir           1\n",
      "Mme           1\n",
      "Don           1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Name: Name, dtype: int64\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Sir           1\n",
      "Mme           1\n",
      "Don           1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    #If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles\n",
    "titles = train_df[\"Name\"].apply(get_title)\n",
    "\n",
    "#Add in the title column with all the current values so we can then manually change them\n",
    "train_df[\"Title\"] = titles\n",
    "# Check count of title values to give the list of titles that need to be changed\n",
    "# print(pd.value_counts(titles))\n",
    "\n",
    "# Titles with very low cell counts to be combined to \"rare\" level\n",
    "rare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n",
    "                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n",
    "\n",
    "# Also reassign mlle, ms, and mme accordingly\n",
    "train_df.loc[train_df[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\n",
    "train_df.loc[train_df[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\n",
    "train_df.loc[train_df[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\n",
    "train_df.loc[train_df[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\n",
    "train_df.loc[train_df[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n",
    "\n",
    "titles = train_df[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "#Add in the title column.\n",
    "test_df[\"Title\"] = titles\n",
    "\n",
    "# Titles with very low cell counts to be combined to \"rare\" level\n",
    "rare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n",
    "                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n",
    "\n",
    "# Also reassign mlle, ms, and mme accordingly\n",
    "test_df.loc[test_df[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\n",
    "test_df.loc[test_df[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\n",
    "test_df.loc[test_df[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\n",
    "test_df.loc[test_df[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\n",
    "test_df.loc[test_df[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr            228\n",
       "Miss          101\n",
       "Mrs            59\n",
       "Master         23\n",
       "Rare Title      7\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['Agebin'] = pd.cut(train_df['Age'],[0,10,20,30,40,50,60,70,80])\n",
    "test_df['Agebin'] = pd.cut(test_df['Age'],[0,10,20,30,40,50,60,70,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (20, 30]\n",
       "1      (30, 40]\n",
       "2      (20, 30]\n",
       "3      (30, 40]\n",
       "4      (30, 40]\n",
       "5      (20, 30]\n",
       "6      (50, 60]\n",
       "7       (0, 10]\n",
       "8      (20, 30]\n",
       "9      (10, 20]\n",
       "10      (0, 10]\n",
       "11     (50, 60]\n",
       "12     (10, 20]\n",
       "13     (30, 40]\n",
       "14     (10, 20]\n",
       "15     (50, 60]\n",
       "16      (0, 10]\n",
       "17     (30, 40]\n",
       "18     (30, 40]\n",
       "19     (20, 30]\n",
       "20     (30, 40]\n",
       "21     (30, 40]\n",
       "22     (10, 20]\n",
       "23     (20, 30]\n",
       "24      (0, 10]\n",
       "25     (30, 40]\n",
       "26     (20, 30]\n",
       "27     (10, 20]\n",
       "28     (20, 30]\n",
       "29     (20, 30]\n",
       "         ...   \n",
       "861    (20, 30]\n",
       "862    (40, 50]\n",
       "863    (10, 20]\n",
       "864    (20, 30]\n",
       "865    (40, 50]\n",
       "866    (20, 30]\n",
       "867    (30, 40]\n",
       "868    (20, 30]\n",
       "869     (0, 10]\n",
       "870    (20, 30]\n",
       "871    (40, 50]\n",
       "872    (30, 40]\n",
       "873    (40, 50]\n",
       "874    (20, 30]\n",
       "875    (10, 20]\n",
       "876    (10, 20]\n",
       "877    (10, 20]\n",
       "878    (20, 30]\n",
       "879    (50, 60]\n",
       "880    (20, 30]\n",
       "881    (30, 40]\n",
       "882    (20, 30]\n",
       "883    (20, 30]\n",
       "884    (20, 30]\n",
       "885    (30, 40]\n",
       "886    (20, 30]\n",
       "887    (10, 20]\n",
       "888    (10, 20]\n",
       "889    (20, 30]\n",
       "890    (30, 40]\n",
       "Name: Agebin, dtype: category\n",
       "Categories (8, object): [(0, 10] < (10, 20] < (20, 30] < (30, 40] < (40, 50] < (50, 60] < (60, 70] < (70, 100]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Agebin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Agebin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket  Fare Cabin  Embarked  Title  Agebin  \n",
       "0         A/5 21171     7   NaN         2      2       2  \n",
       "1          PC 17599    71   C85         0      3       3  \n",
       "2  STON/O2. 3101282     7   NaN         2      1       2  \n",
       "3            113803    53  C123         2      3       3  \n",
       "4            373450     8   NaN         2      2       3  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "labelEnc=LabelEncoder()\n",
    "\n",
    "cat_vars=['Embarked','Sex','Title','Agebin']\n",
    "for col in cat_vars:\n",
    "    train_df[col]=labelEnc.fit_transform(train_df[col])\n",
    "    test_df[col]=labelEnc.fit_transform(test_df[col])\n",
    "\n",
    "train_df.head()\n",
    "train_df.describe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
